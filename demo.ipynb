{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Description :   \n",
    "@Author      :   Xubo Luo \n",
    "@Time        :   2024/07/10 20:09:58\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from lightglue.lightglue import LightGlue\n",
    "from lightglue.superpoint import SuperPoint\n",
    "from xfeat.xfeat import XFeat\n",
    "\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from: weights/xfeat.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuaodi/workspace/Codes/dev/FastMatch/lightglue/lightglue.py:143: UserWarning: FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.\n",
      "  self.inner_attn = Attention(flash)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
    "xfeat = XFeat(weights='weights/xfeat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse_input() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m image1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m./assets/tgt.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Extract keypoints and descriptors\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m image0 \u001b[39m=\u001b[39m XFeat\u001b[39m.\u001b[39;49mparse_input(image0)\n\u001b[1;32m      6\u001b[0m image1 \u001b[39m=\u001b[39m XFeat\u001b[39m.\u001b[39mparse_input(image1)\n\u001b[1;32m      8\u001b[0m feat0 \u001b[39m=\u001b[39m XFeat\u001b[39m.\u001b[39mdetectAndCompute(image0, top_k \u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: parse_input() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "image0 = cv2.imread(\"./assets/ref.png\")\n",
    "image1 = cv2.imread(\"./assets/tgt.png\")\n",
    "\n",
    "# Extract keypoints and descriptors\n",
    "image0 = XFeat.parse_input(image0)\n",
    "image1 = XFeat.parse_input(image1)\n",
    "\n",
    "feat0 = XFeat.detectAndCompute(image0, top_k = 2048)[0]\n",
    "feat1 = XFeat.detectAndCompute(image1, top_k = 2048)[0]\n",
    "\n",
    "kpts0, desc0 = feat0[\"keypoints\"], feat0[\"descriptors\"]\n",
    "kpts1, desc1 = feat1[\"keypoints\"], feat1[\"descriptors\"]\n",
    "\n",
    "kpts0 = kpts0.unsqueeze(0)\n",
    "kpts1 = kpts1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matches01 \u001b[39m=\u001b[39m matcher({\u001b[39m\"\u001b[39m\u001b[39mimage0\u001b[39m\u001b[39m\"\u001b[39m:feat0, \u001b[39m\"\u001b[39m\u001b[39mimage1\u001b[39m\u001b[39m\"\u001b[39m:feat1})\n\u001b[1;32m      3\u001b[0m feat0, feat1, matches01 \u001b[39m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     rbd(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (feat0, feat1, matches01)\n\u001b[1;32m      5\u001b[0m ]   \u001b[39m# remove batch dimension\u001b[39;00m\n\u001b[1;32m      7\u001b[0m kpts0, kpts1, matches \u001b[39m=\u001b[39m feat0[\u001b[39m\"\u001b[39m\u001b[39mkeypoints\u001b[39m\u001b[39m\"\u001b[39m], feat1[\u001b[39m\"\u001b[39m\u001b[39mkeypoints\u001b[39m\u001b[39m\"\u001b[39m], matches01[\u001b[39m\"\u001b[39m\u001b[39mmatches\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matcher' is not defined"
     ]
    }
   ],
   "source": [
    "matches01 = matcher({\"image0\":feat0, \"image1\":feat1})\n",
    "\n",
    "feat0, feat1, matches01 = [\n",
    "    rbd(x) for x in (feat0, feat1, matches01)\n",
    "]   # remove batch dimension\n",
    "\n",
    "kpts0, kpts1, matches = feat0[\"keypoints\"], feat1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers', fs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
